data:
  dataset_path: "data/raw/CEAS_08.csv"

  train_split: 0.8
  val_split: 0.1
  test_split: 0.1

  batch_size: 32

  max_tokens: 2000



model:
  model_type: "fnn"

  # Google NNLM en-128 embedding dimension
  embedding_dim: 128

  hidden_dim: 16

  # Number of dense+dropout blocks
  num_layers: 2

  dropout_rate: 0.2



train:
  epochs: 5

  optimizer: "adamw"

  learning_rate: 0.001

  seed: 42



output_dir: "results/feedforward_double_dr02/"
